import logging
import random
from datetime import datetime
from typing import Any, Dict, List

from aiogram import F, Router, types
from aiogram.fsm.context import FSMContext
from aiogram.types import InlineKeyboardMarkup

from db.crud import TrainingCRUD, VocabCRUD, WordpairCRUD
from db.database import Session
from exceptions import InvalidVocabIndexError
from src.filters.check_empty_filters import CheckEmptyFilter
from src.fsm.states import VocabTraining
from src.keyboards.vocab_trainer_kb import (
    get_kb_all_training,
    get_kb_confirm_cancel_training,
    get_kb_finish_training,
    get_kb_process_training,
    get_kb_vocab_selection_training,
)
from text_data import (
    MSG_CHOOSE_TRAINING_MODE,
    MSG_CHOOSE_VOCAB_FOR_TRAINING,
    MSG_CONFIRM_CANCEL_TRAINING,
    MSG_INFO_VOCAB_BASE_EMPTY_FOR_TRAINING,
)
from tools.training_utils import format_training_message
from tools.wordpair_utils import format_word_items

router = Router(name='vocab_trainer')
logger: logging.Logger = logging.getLogger(__name__)


@router.callback_query(F.data == 'vocab_trainer')
async def process_vocab_base(callback: types.CallbackQuery, state: FSMContext) -> None:
    """–í—ñ–¥—Å—Ç–µ–∂—É—î –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—è –Ω–∞ –∫–Ω–æ–ø–∫—É "–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è" —É –≥–æ–ª–æ–≤–Ω–æ–º—É –º–µ–Ω—é.
    –í—ñ–¥–ø—Ä–∞–≤–ª—è—î –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫—ñ —Å–ª–æ–≤–Ω–∏–∫–∏ —É –≤–∏–≥–ª—è–¥—ñ –∫–Ω–æ–ø–æ–∫.
    """
    user_id: int = callback.from_user.id

    logger.info(f'–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á –ø–µ—Ä–µ–π—à–æ–≤ –¥–æ —Ä–æ–∑–¥—ñ–ª—É "–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è". USER_ID: {user_id}')

    check_empty_filter = CheckEmptyFilter()

    await state.clear()
    logger.info('FSM —Å—Ç–∞–Ω —Ç–∞ FSM-Cache –æ—á–∏—â–µ–Ω–æ')

    with Session() as session:
        vocab_crud = VocabCRUD(session)

        # –î–∞–Ω—ñ –≤—Å—ñ—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏—Ö —Å–ª–æ–≤–Ω–∏–∫—ñ–≤ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        all_vocabs_data: list[dict] = vocab_crud.get_all_vocabs_data(user_id)

    # –Ø–∫—â–æ –≤ –ë–î –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –Ω–µ–º–∞—î –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏—Ö —Å–ª–æ–≤–Ω–∏–∫—ñ–≤
    if check_empty_filter.apply(all_vocabs_data):
        logger.info('–í –ë–î –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –Ω–µ–º–∞—î –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏—Ö —Å–ª–æ–≤–Ω–∏–∫—ñ–≤')
        msg_text: str = MSG_INFO_VOCAB_BASE_EMPTY_FOR_TRAINING
        kb: InlineKeyboardMarkup = get_kb_vocab_selection_training(all_vocabs_data, is_with_btn_vocab_base=True)
    else:
        msg_text: str = MSG_CHOOSE_VOCAB_FOR_TRAINING
        kb: InlineKeyboardMarkup = get_kb_vocab_selection_training(all_vocabs_data)
    await callback.message.edit_text(text=msg_text, reply_markup=kb)


@router.callback_query(F.data.startswith('select_vocab_training'))
async def process_training_selection(callback: types.CallbackQuery, state: FSMContext) -> None:
    """–í—ñ–¥—Å—Ç–µ–∂—É—î –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—è –Ω–∞ –∫–Ω–æ–ø–∫—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–æ–≥–æ —Å–ª–æ–≤–Ω–∏–∫–∞ —É —Ä–æ–∑–¥—ñ–ª—ñ "–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è".
    –í—ñ–¥–ø—Ä–∞–≤–ª—è—î –∫–ª–∞–≤—ñ–∞—Ç—É—Ä—É –∑ –≤–∏–±–æ—Ä–æ–º —Ç–∏–ø—É —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è.
    """
    vocab_id = int(callback.data.split('_')[-1])
    logger.info(f'–ë—É–≤ –æ–±—Ä–∞–Ω–∏–π –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏–π —Å–ª–æ–≤–Ω–∏–∫ —É —Ä–æ–∑–¥—ñ–ª—ñ "–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è". VOCAB_ID: {vocab_id}')

    try:
        with Session() as session:
            vocab_crud = VocabCRUD(session)
            vocab_data: dict[str, Any] = vocab_crud.get_vocab_data(vocab_id)

            wordpair_crud = WordpairCRUD(session)
            wordpair_items: list[dict] = wordpair_crud.get_wordpairs(vocab_id)
    except InvalidVocabIndexError as e:
        logger.error(e)
        return

    kb: InlineKeyboardMarkup = get_kb_all_training()
    vocab_name: str = vocab_data.get('name')
    msg_choose_training_mode: str = MSG_CHOOSE_TRAINING_MODE.format(name=vocab_name)

    wordpairs_count: int = vocab_data.get('wordpairs_count')

    await state.update_data(vocab_id=vocab_id,
                            vocab_data=vocab_data,
                            wordpair_items=wordpair_items,
                            wordpairs_count=wordpairs_count)
    logger.info('ID –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–æ–≥–æ —Å–ª–æ–≤–Ω–∏–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–∏–π —É FSM-Cache')

    await callback.message.edit_text(text=msg_choose_training_mode, reply_markup=kb)


@router.callback_query(F.data == 'direct_translation')
async def process_btn_direct_translation(callback: types.CallbackQuery, state: FSMContext) -> None:
    """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö —É FSM"""
    await callback.message.delete()

    data_fsm: dict[str, Any] = await state.get_data()
    wordpairs_count: int = data_fsm.get('wordpairs_count')
    start_time_training: datetime = datetime.now()
    await state.update_data(start_time_training=start_time_training)
    # –°–ø–∏—Å–æ–∫ —ñ–Ω–¥–µ–∫—Å—ñ–≤, —è–∫—ñ —â–µ –Ω–µ –±—É–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ
    available_idxs = list(range(wordpairs_count))

    await state.update_data(current_training_mode='direct_translation',
                            available_idxs=available_idxs)
    await send_next_word(callback.message, state)


@router.callback_query(F.data == 'reverse_translation')
async def process_btn_reverse_translation(callback: types.CallbackQuery, state: FSMContext) -> None:
    """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è —ñ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö —É FSM"""
    data_fsm: Dict[str, Any] = await state.get_data()
    vocab_id: int = data_fsm.get('vocab_id')

    with Session() as db:
        vocab_details: List[Dict] = get_wordpairs_by_vocab_id(db, vocab_id)

    # –°–ø–∏—Å–æ–∫ —ñ–Ω–¥–µ–∫—Å—ñ–≤, —è–∫—ñ —â–µ –Ω–µ –±—É–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ
    available_idxs = list(range(len(vocab_details)))

    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤—Å—ñ—Ö –¥–µ—Ç–∞–ª–µ–π —É —Å—Ç–∞–Ω—ñ FSM
    await state.update_data(vocab_details=vocab_details, available_idxs=available_idxs, current_training_type='reverse_translation')

    # –ù–∞–¥—Å–∏–ª–∞—î–º–æ –ø–µ—Ä—à—É –ø–∞—Ä—É –Ω–∞ –ø–µ—Ä–µ–∫–ª–∞–¥
    await send_next_word(callback.message, state)


def get_random_wordpair_idx(available_idxs: list, preview_idx: int) -> int:
    """–ü–æ–≤–µ—Ä—Ç–∞—î –≤–∏–ø–∞–¥–∫–æ–≤–∏–π —ñ–Ω–¥–µ–∫—Å —Å–ª–æ–≤–Ω–∏–∫–æ–≤–æ—ó –ø–∞—Ä–∏ —ñ–∑ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö.
    –Ø–∫—â–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∏—Ö —ñ–Ω–¥–µ–∫—Å—ñ–≤ –±—ñ–ª—å—à–∞ –∑–∞ –æ–¥–∏–Ω, —Ç–æ –æ–±—Ä–∞–Ω–∏–π –Ω–æ–≤–∏–π —ñ–Ω–¥–µ–∫—Å –Ω–µ –ø–æ–≤–∏–Ω–µ–Ω –∑–±—ñ–≥–∞—Ç–∏—Å—è –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–º.

    Args:
        available_idxs (list): –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö —ñ–Ω–¥–µ–∫—Å—ñ–≤.
        preview_idx (int): –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π —ñ–Ω–¥–µ–∫—Å.

    Returns:
        int: –í–∏–ø–∞–¥–∫–æ–≤–∏–π —ñ–Ω–¥–µ–∫—Å.
    """
    if len(available_idxs) == 1:
        return available_idxs[0]

    # –Ø–∫—â–æ —ñ–Ω–¥–µ–∫—Å—ñ–≤ –±—ñ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ, —Ç–æ –æ–±–∏—Ä–∞—î—Ç—å—Å—è –Ω–æ–≤–∏–π —ñ–Ω–¥–µ–∫—Å
    wordpair_idx: int = random.choice(available_idxs)
    while wordpair_idx == preview_idx:
        wordpair_idx: int = random.choice(available_idxs)

    return wordpair_idx


async def send_next_word(message: types.Message, state: FSMContext) -> None:
    """–í—ñ–¥–ø—Ä–∞–≤–ª—è—î –Ω–∞—Å—Ç—É–ø–Ω–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–µ—Ä–µ–∫–ª–∞–¥—É"""
    data_fsm: dict[str, Any] = await state.get_data()

    # –ü—Ä–∞–ø–æ—Ä –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –ø–æ—Ç–æ—á–Ω–µ —Å–ª–æ–≤–æ —á–∏ –æ–±—Ä–∞—Ç–∏ –Ω–æ–≤–µ
    use_current_word: bool = data_fsm.get('use_current_word', False)

    vocab_data: dict[str, Any] = data_fsm.get('vocab_data')
    wordpair_items: list[dict] = data_fsm.get('wordpair_items')

    vocab_name: str = vocab_data.get('name')
    available_idxs: list = data_fsm.get('available_idxs', [])  # –°–ø–∏—Å–æ–∫ —ñ–Ω–¥–µ–∫—Å—ñ–≤, —è–∫—ñ —â–µ –Ω–µ –±—É–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ

    current_training_mode: str = data_fsm.get('current_training_mode')  # –¢–∏–ø —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è

    training_number_errors: int = data_fsm.get('training_number_errors', 0)  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–º–∏–ª–æ–∫ –∑–∞ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è
    current_training_count: int = data_fsm.get('current_training_count', 1)  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç—Ä–µ–Ω—É–≤–∞–Ω—å –ø–æ—Å–ø—ñ–ª—å

    check_empty_filter = CheckEmptyFilter()

    # –Ø–∫—â–æ –Ω–µ –∑–∞–ª–∏—à–∏–ª–æ—Å—å –Ω–µ–≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏—Ö —ñ–Ω–¥–µ–∫—Å—ñ–≤
    if check_empty_filter.apply(available_idxs):
        kb: InlineKeyboardMarkup = get_kb_finish_training()

        msg_choose_training_mode: str = MSG_CHOOSE_TRAINING_MODE.format(name=vocab_name)
        msg_text: str = f'–í—Å—ñ —Å–ª–æ–≤–Ω–∏–∫–æ–≤—ñ –ø–∞—Ä–∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ñ. –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\n\n{msg_choose_training_mode}'
        await state.update_data(training_number_errors=0,
                                training_is_completed=True)

        await finish_training(message, state)
        await message.answer(text=msg_text, reply_markup=kb)
        return

    preview_wordpair_idx: int = data_fsm.get('wordpair_idx', 0)  # –ú–∏–Ω—É–ª–∏–π —ñ–Ω–¥–µ–∫—Å

    if use_current_word:
        wordpair_idx: int = preview_wordpair_idx
        await state.update_data(use_current_word=False)
    else:
        # –í–∏–±—ñ—Ä –≤–∏–ø–∞–¥–∫–æ–≤–æ–≥–æ —ñ–Ω–¥–µ–∫—Å—É –∑ —Ç–∏—Ö, —â–æ —â–µ –Ω–µ –±—É–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ
        wordpair_idx: int = get_random_wordpair_idx(available_idxs, preview_wordpair_idx)
    await state.update_data(wordpair_idx=wordpair_idx)

    wordpair_item: dict[str, Any] = wordpair_items[wordpair_idx]

    # –°–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö —Å–ª—ñ–≤ —Ç–∞ –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤ —Å–ª–æ–≤–Ω–∏–∫–æ–≤–æ—ó –ø–∞—Ä–∏ –∑ —ó—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è–º–∏
    word_items: list[dict] = wordpair_item.get('words')
    translation_items: list[dict] = wordpair_item.get('translations')
    wordpair_annotation = wordpair_item.get('annotation') or '–í—ñ–¥—Å—É—Ç–Ω—è'

    if current_training_mode == 'direct_translation':
        formatted_words: str = format_word_items(word_items)
        formatted_translations: str = format_word_items(translation_items, is_translation_items=True)
        correct_translations: list = [translation.get('translation').lower() for translation in translation_items]
    elif current_training_mode == 'reverse_translation':
        formatted_words: str = format_word_items(translation_items, is_translation_items=True)
        formatted_translations: str = format_word_items(word_items)
        correct_translations: list = [translation.get('word').lower() for translation in word_items]

    await state.update_data(wordpair_annotation=wordpair_annotation,
                            formatted_words=formatted_words,
                            formatted_translations=formatted_translations,
                            wordpair_idx=wordpair_idx,
                            correct_translations=correct_translations)

    kb: InlineKeyboardMarkup = get_kb_process_training()  # –ö–ª–∞–≤—ñ–∞—Ç—É—Ä–∞ –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è
    msg_enter_translation: str = format_training_message(vocab_name=vocab_name,
                                                         training_mode=current_training_mode,
                                                         training_count=current_training_count,
                                                         number_errors=training_number_errors,
                                                         word=formatted_words)
    await message.answer(text=msg_enter_translation, reply_markup=kb)

    # –û–Ω–æ–≤–ª—é—î–º–æ —Å—Ç–∞–Ω –Ω–∞ –æ—á—ñ–∫—É–≤–∞–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    await state.set_state(VocabTraining.waiting_for_translation)


@router.message(VocabTraining.waiting_for_translation)
async def process_translation(message: types.Message, state: FSMContext) -> None:
    """–û–±—Ä–æ–±–ª—è—î –ø–µ—Ä–µ–∫–ª–∞–¥, –≤–≤–µ–¥–µ–Ω–∏–π –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º"""
    data_fsm: dict[str, Any] = await state.get_data()

    wordpair_idx = data_fsm.get('wordpair_idx')

    formatted_words = data_fsm.get('formatted_words')
    formatted_translations = data_fsm.get('formatted_translations')

    available_idxs = data_fsm.get('available_idxs', [])  # –°–ø–∏—Å–æ–∫ —ñ–Ω–¥–µ–∫—Å—ñ–≤, —è–∫—ñ —â–µ –Ω–µ –±—É–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ
    correct_translations = data_fsm.get('correct_translations')

    # –ü–µ—Ä–µ–∫–ª–∞–¥–∏ –±–µ–∑ –∞–Ω–æ—Ç–∞—Ü—ñ–π
    print(correct_translations)
    user_translation: str = message.text.strip().lower()  # –í–≤–µ–¥–µ–Ω–∏–π –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º –ø–µ—Ä–µ–∫–ª–∞–¥
    print(user_translation)
    if user_translation in correct_translations:
        await message.answer(f'–ü—Ä–∞–≤–∏–ª—å–Ω–æ!\n{formatted_words} -> {formatted_translations}')
        available_idxs.remove(wordpair_idx)
        number_correct_answers = data_fsm.get('number_correct_answers', 0)
        await state.update_data(available_idxs=available_idxs,
                                number_correct_answers=number_correct_answers + 1)  # –û–Ω–æ–≤–ª–µ–Ω–Ω—è —ñ–Ω–¥–µ–∫—Å—É
        await send_next_word(message, state)
    else:
        training_number_errors: int = data_fsm.get('training_number_errors', 0)  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–º–∏–ª–æ–∫ –∑–∞ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è
        await state.update_data(training_number_errors=training_number_errors + 1)
        await message.answer('–ù–µ –ü—Ä–∞–≤–∏–ª—å–Ω–æ!')
        await send_next_word(message, state)


@router.callback_query(F.data == 'skip_word')
async def process_skip_word(callback: types.CallbackQuery, state: FSMContext) -> None:
    """–í—ñ–¥—Å—Ç–µ–∂—É—î –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—è –Ω–∞ –∫–Ω–æ–ø–∫—É "–ü–æ–≤—Ç–æ—Ä–∏—Ç–∏ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è" –ø—ñ–¥ —á–∞—Å —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è"""
    await callback.message.delete()

    data_fsm: dict[str, Any] = await state.get_data()
    available_idxs: list = data_fsm.get('available_idxs', [])  # –°–ø–∏—Å–æ–∫ —ñ–Ω–¥–µ–∫—Å—ñ–≤, —è–∫—ñ —â–µ –Ω–µ –±—É–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ
    if len(available_idxs) == 1:
        await callback.message.answer('–ó–∞–ª–∏—à–∏–ª–æ—Å—å –æ–¥–Ω–µ —Å–ª–æ–≤–æ, –Ω–µ –º–æ–∂–Ω–∞ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–∏!')
    await send_next_word(callback.message, state)


@router.callback_query(F.data == 'show_annotation')
async def process_show_annotation(callback: types.CallbackQuery, state: FSMContext) -> None:
    """–í—ñ–¥—Å—Ç–µ–∂—É—î –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—è –Ω–∞ –∫–Ω–æ–ø–∫—É "–ü–æ–≤—Ç–æ—Ä–∏—Ç–∏ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è" –ø—ñ–¥ —á–∞—Å —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è"""
    await callback.message.delete()

    data_fsm: dict[str, Any] = await state.get_data()
    wordpair_annotation: str = data_fsm.get('wordpair_annotation')
    words: str = data_fsm.get('formatted_words')
    await state.update_data(use_current_word=True)
    await callback.message.answer(f'–°–ª–æ–≤–æ(–∞): {words}\n–ê–Ω–æ—Ç–∞—Ü—ñ—è: {wordpair_annotation}')
    await send_next_word(callback.message, state)


@router.callback_query(F.data == 'show_translation')
async def process_show_translation(callback: types.CallbackQuery, state: FSMContext) -> None:
    """–í—ñ–¥—Å—Ç–µ–∂—É—î –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—è –Ω–∞ –∫–Ω–æ–ø–∫—É "–ü–æ–≤—Ç–æ—Ä–∏—Ç–∏ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è" –ø—ñ–¥ —á–∞—Å —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è"""
    await callback.message.delete()

    data_fsm: dict[str, Any] = await state.get_data()
    wordpair_annotation: str = data_fsm.get('wordpair_annotation')
    words: str = data_fsm.get('formatted_words')
    translations: str = data_fsm.get('formatted_translations')
    available_idxs: list = data_fsm.get('available_idxs', [])  # –°–ø–∏—Å–æ–∫ —ñ–Ω–¥–µ–∫—Å—ñ–≤, —è–∫—ñ —â–µ –Ω–µ –±—É–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ
    wordpair_idx = data_fsm.get('wordpair_idx')
    number_wrong_answers = data_fsm.get('number_wrong_answers', 0)
    await callback.message.answer(f'–°–ª–æ–≤–æ(–∞): {words}\n–ü–µ—Ä–µ–∫–ª–∞–¥(–∏): {translations}\n–ê–Ω–æ—Ç–∞—Ü—ñ—è: {wordpair_annotation}')
    available_idxs.remove(wordpair_idx)
    await state.update_data(available_idxs=available_idxs,
                            number_wrong_answers=number_wrong_answers + 1)  # –û–Ω–æ–≤–ª–µ–Ω–Ω—è —ñ–Ω–¥–µ–∫—Å—É
    await send_next_word(callback.message, state)


@router.callback_query(F.data == 'repeat_training')
async def process_repeat_training(callback: types.CallbackQuery, state: FSMContext) -> None:
    """–í—ñ–¥—Å—Ç–µ–∂—É—î –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—è –Ω–∞ –∫–Ω–æ–ø–∫—É "–ü–æ–≤—Ç–æ—Ä–∏—Ç–∏ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è" –ø—ñ–¥ —á–∞—Å —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è"""
    await callback.message.delete()

    data_fsm: dict[str, Any] = await state.get_data()
    wordpairs_count: int = data_fsm.get('wordpairs_count')

    available_idxs = list(range(wordpairs_count))
    current_training_count: int = data_fsm.get('current_training_count', 1)  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç—Ä–µ–Ω—É–≤–∞–Ω—å –ø–æ—Å–ø—ñ–ª—å
    start_time_training: datetime = datetime.now()

    await state.update_data(available_idxs=available_idxs,
                            start_time_training=start_time_training,
                            current_training_count=current_training_count + 1)  # –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Å–ø–∏—Å–∫—É –Ω–µ–≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏—Ö —ñ–Ω–¥–µ–∫—Å—ñ–≤
    await send_next_word(callback.message, state)


@router.callback_query(F.data == 'change_training_mode')
async def process_change_training_mode(callback: types.CallbackQuery, state: FSMContext) -> None:
    """–í—ñ–¥—Å—Ç–µ–∂—É—î –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—è –Ω–∞ –∫–Ω–æ–ø–∫—É "–ó–º—ñ–Ω–∏—Ç–∏ —Ç–∏–ø —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è" –ø—ñ–¥ —á–∞—Å —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è"""
    data_fsm: dict[str, Any] = await state.get_data()
    wordpairs_count: int = data_fsm.get('wordpairs_count')

    available_idxs = list(range(wordpairs_count))
    await state.update_data(available_idxs=available_idxs)  # –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Å–ø–∏—Å–∫—É –Ω–µ–≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏—Ö —ñ–Ω–¥–µ–∫—Å—ñ–≤

    kb: InlineKeyboardMarkup = get_kb_all_training()
    vocab_name: str = data_fsm.get('vocab_name')
    msg_choose_training_mode: str = MSG_CHOOSE_TRAINING_MODE.format(name=vocab_name)

    await callback.message.edit_text(text=msg_choose_training_mode, reply_markup=kb)


@router.callback_query(F.data == 'cancel_training')
async def process_cancel_training(callback: types.CallbackQuery) -> None:
    """–í—ñ–¥—Å—Ç–µ–∂—É—î –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—è –Ω–∞ –∫–Ω–æ–ø–∫—É "–°–∫–∞—Å—É–≤–∞—Ç–∏" –ø—ñ–¥ —á–∞—Å —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è.
    –í—ñ–¥–ø—Ä–∞–≤–ª—è—î –∫–ª–∞–≤—ñ–∞—Ç—É—Ä—É –¥–ª—è –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è —Å–∫–∞—Å—É–≤–∞–Ω–Ω—è.
    """
    kb: InlineKeyboardMarkup = get_kb_confirm_cancel_training()
    msg_confirm_cancel_training: str = MSG_CONFIRM_CANCEL_TRAINING

    await callback.message.edit_text(text=msg_confirm_cancel_training, reply_markup=kb)


@router.callback_query(F.data == 'accept_cancel_training')
async def process_accept_cancel_training(callback: types.CallbackQuery, state: FSMContext) -> None:
    """–í—ñ–¥—Å—Ç–µ–∂—É—î –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—è –Ω–∞ –∫–Ω–æ–ø–∫—É "–¢–∞–∫" –ø—Ä–∏ –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—ñ –≤–∏–¥–∞–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–æ–≥–æ —Å–ª–æ–≤–Ω–∏–∫–∞.
    –ú º—è–∫–æ –≤–∏–¥–∞–ª—è—î –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏–π —Å–ª–æ–≤–Ω–∏–∫, –∑–∞–ª–∏—à–∞—é—á–∏ –≤—Å—ñ –π–æ–≥–æ –∑–≤ º—è–∑–∫–∏ –≤ –ë–î.
    """
    data_fsm: dict[str, Any] = await state.get_data()
    wordpairs_count: int = data_fsm.get('wordpairs_count')
    number_wrong_answers = data_fsm.get('number_wrong_answers', 0)

    available_idxs = list(range(wordpairs_count))
    await state.update_data(available_idxs=available_idxs,
                            number_wrong_answers=number_wrong_answers + len(available_idxs),
                            training_is_completed=False)  # –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Å–ø–∏—Å–∫—É –Ω–µ–≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏—Ö —ñ–Ω–¥–µ–∫—Å—ñ–≤

    kb: InlineKeyboardMarkup = get_kb_all_training()
    await finish_training(callback.message, state)
    msg_text = '–í–∏ —Å–∫–∞—Å—É–≤–∞–ª–∏ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è'
    await callback.message.edit_text(text=msg_text, reply_markup=kb)


@router.callback_query(F.data == 'decline_cancel_training')
async def process_decline_cancel_training(callback: types.CallbackQuery, state: FSMContext) -> None:
    """–í—ñ–¥—Å—Ç–µ–∂—É—î –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—è –Ω–∞ –∫–Ω–æ–ø–∫—É "–¢–∞–∫" –ø—Ä–∏ –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—ñ –≤–∏–¥–∞–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–æ–≥–æ —Å–ª–æ–≤–Ω–∏–∫–∞.
    –ú º—è–∫–æ –≤–∏–¥–∞–ª—è—î –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏–π —Å–ª–æ–≤–Ω–∏–∫, –∑–∞–ª–∏—à–∞—é—á–∏ –≤—Å—ñ –π–æ–≥–æ –∑–≤ º—è–∑–∫–∏ –≤ –ë–î.
    """
    await send_next_word(callback.message, state)


async def finish_training(message: types.Message, state: FSMContext) -> None:
    """–ó–∞–≤–µ—Ä—à–µ–Ω–Ω—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è —ñ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —É –±–∞–∑—ñ –¥–∞–Ω–∏—Ö."""

    # –û—Ç—Ä–∏–º—É—î–º–æ –¥–∞–Ω—ñ –∑—ñ —Å—Ç–∞–Ω—É
    data_fsm: dict[str, Any] = await state.get_data()

    user_id: int = message.from_user.id
    vocab_name = data_fsm.get('name')
    vocab_id = data_fsm.get('vocab_id')
    current_training_mode = data_fsm.get('current_training_mode')
    start_time_training = data_fsm.get('start_time_training')
    end_time_training = datetime.now()
    number_correct_answers = data_fsm.get('number_correct_answers', 0)
    number_wrong_answers = data_fsm.get('number_wrong_answers', 0)
    training_is_completed = data_fsm.get('training_is_completed', True)

    # –û–±—á–∏—Å–ª—é—î–º–æ —Ä—ñ–∑–Ω–∏—Ü—é
    duration_training = end_time_training - start_time_training

    # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ö–≤–∏–ª–∏–Ω —ñ —Å–µ–∫—É–Ω–¥
    training_time_minutes = duration_training.seconds // 60  # –¶—ñ–ª—ñ —Ö–≤–∏–ª–∏–Ω–∏
    training_time_seconds = duration_training.seconds % 60   # –ó–∞–ª–∏—à–∫–æ–≤—ñ —Å–µ–∫—É–Ω–¥–∏

    with Session() as session:
        training_crud = TrainingCRUD(session)
        training_crud.create_new_training_session(user_id=user_id,
                                                vocabulary_id=vocab_id,
                                                training_mode=current_training_mode,
                                                start_time=start_time_training,
                                                end_time=end_time_training,
                                                number_correct_answers=number_correct_answers,
                                                number_wrong_answers=number_wrong_answers,
                                                is_completed=training_is_completed)

    # –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–≤—ñ
    await message.answer(
        f"–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\n"
        f'–°–ª–æ–≤–Ω–∏–∫: {vocab_name}'
        f"‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: {number_correct_answers}\n"
        f"‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: {number_wrong_answers}\n"
        f'–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è: {training_time_minutes} —Ö–≤–∏–ª–∏–Ω, {training_time_seconds} —Å–µ–∫—É–Ω–¥'
        f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–∞."
    )

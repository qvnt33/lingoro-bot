import random
from typing import Any

from qx3learn_bot.tools.wordpair_utils import format_word_items


def format_training_process_message(vocab_name: str,
                                    training_mode: str,
                                    wordpairs_left: int,
                                    total_wordpairs_count: int,
                                    words: str) -> str:
    """–§–æ—Ä–º–∞—Ç—É—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—î—é –ø—ñ–¥ —á–∞—Å —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è.

    Args:
        vocab_name (str): –ù–∞–∑–≤–∞ —Å–ª–æ–≤–Ω–∏–∫–∞.
        training_mode (str): –¢–∏–ø —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è.
        wordpairs_left (int): –°–∫—ñ–ª—å–∫–∏ –ø—Ä–æ–π–¥–µ–Ω–æ (–ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω–æ —á–∏ –ø—Ä–æ–ø—É—â–µ–Ω–æ) —Å–ª–æ–≤–Ω–∏–∫–æ–≤–∏—Ö –ø–∞—Ä.
        total_wordpairs_count (int): –°–∫—ñ–ª—å–∫–∏ –≤—Å—ñ—Ö —Å–ª–æ–≤–Ω–∏–∫–æ–≤–∏—Ö –ø–∞—Ä —É —Å–ª–æ–≤–Ω–∏–∫—É.
        words (str): –í—ñ–¥—Ñ–æ—Ä–º–∞—Ç–æ–≤–∞–Ω–µ —Å–ª–æ–≤–æ(–∞) (—Å–ª–æ–≤–∞+—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó)
    """
    summary_message: str = (
        f'üìó –°–ª–æ–≤–Ω–∏–∫: {vocab_name}\n'
        f'üéØ –¢–∏–ø —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è: {training_mode}\n\n'
        f'üìã –ü—Ä–æ–≥—Ä–µ—Å: {wordpairs_left} / {total_wordpairs_count}\n\n'
        f'üîª –ü–µ—Ä–µ–∫–ª–∞–¥—ñ—Ç—å —Å–ª–æ–≤–æ(–∞):\n'
        f'{words}')
    return summary_message


def format_training_summary_message(vocab_name: str,
                                    training_mode: str,
                                    training_streak_count: int,
                                    correct_answer_count: int,
                                    wrong_answer_count: int,
                                    annotation_shown_count: int,
                                    translation_shown_count: int,
                                    training_time_minutes: int,
                                    training_time_seconds: int) -> str:
    """–§–æ—Ä–º–∞—Ç—É—î –ø—ñ–¥—Å—É–º–∫–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑—ñ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—î—é –ø—Ä–æ –∑–∞–≤–µ—Ä—à–µ–Ω–µ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è.

    Args:
        vocab_name (str): –ù–∞–∑–≤–∞ —Å–ª–æ–≤–Ω–∏–∫–∞.
        training_mode (str): –¢–∏–ø —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è.
        training_streak_count (int): –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø—Ä–æ–π–¥–µ–Ω–∏—Ö —Ç—Ä–µ–Ω—É–≤–∞–Ω—å –ø–æ—Å–ø—ñ–ª—å.
        correct_answer_count (int): –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ—Ä–µ–∫—Ç–Ω–æ –ø–µ—Ä–µ–∫–ª–∞–¥–∞–Ω–∏—Ö —Å–ª—ñ–≤.
        wrong_answer_count (int): –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–º–∏–ª–æ–∫.
        annotation_shown_count (int): –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–∫–∞–∑—ñ–≤ –∞–Ω–æ—Ç–∞—Ü—ñ–π –∑–∞ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è.
        translation_shown_count (int): –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–∫–∞–∑—ñ–≤ –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤ –∑–∞ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è.
        training_time_minutes (int): –°–∫—ñ–ª—å–∫–∏ —Ö–≤–∏–ª–∏–Ω –π—à–ª–æ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è (–Ω–µ –≤—Ä–∞—Ö–æ–≤—É—é—á–∏ —Å–µ–∫—É–Ω–¥–∏).
        training_time_seconds (int): –°–∫—ñ–ª—å–∫–∏ —Å–µ–∫—É–Ω–¥ –π—à–ª–æ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è (–Ω–µ –≤—Ä–∞—Ö–æ–≤—É—é—á–∏ —Ö–≤–∏–ª–∏–Ω–∏).

    Returns:
        str: –í—ñ–¥—Ñ–æ—Ä–º–∞—Ç–æ–≤–∞–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è.
    """
    summary_message: str = (
        f'üéâ –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\n\n'
        f'üìó –°–ª–æ–≤–Ω–∏–∫: {vocab_name}\n'
        f'üéØ –¢–∏–ø —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è: {training_mode}\n\n'
        f'üî• –ü—Ä–æ–π–¥–µ–Ω–∏—Ö —Ç—Ä–µ–Ω—É–≤–∞–Ω—å –ø–æ—Å–ø—ñ–ª—å: {training_streak_count}\n'
        f'‚úÖ –ö–æ—Ä–µ–∫—Ç–Ω–æ –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω–æ —Å–ª—ñ–≤: {correct_answer_count}\n'
        f'‚ùå –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–º–∏–ª–æ–∫: {wrong_answer_count}\n'
        f'üí° –ü–æ–∫–∞–∑—ñ–≤ –∞–Ω–æ—Ç–∞—Ü—ñ–π: {annotation_shown_count}\n'
        f'üí¨ –ü–æ–∫–∞–∑—ñ–≤ –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤: {translation_shown_count}\n\n'
        f'‚è± –¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è: {training_time_minutes} —Ö–≤–∏–ª–∏–Ω(–∞), {training_time_seconds} —Å–µ–∫—É–Ω–¥(–∞)\n\n'
        '‚û°Ô∏è –û–±–µ—Ä—ñ—Ç—å, —â–æ —Ä–æ–±–∏—Ç–∏ –¥–∞–ª—ñ:')
    return summary_message


def get_random_wordpair_idx(available_idxs: list, preview_idx: int) -> int:
    """–ü–æ–≤–µ—Ä—Ç–∞—î –≤–∏–ø–∞–¥–∫–æ–≤–∏–π —ñ–Ω–¥–µ–∫—Å —Å–ª–æ–≤–Ω–∏–∫–æ–≤–æ—ó –ø–∞—Ä–∏ —ñ–∑ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö.

    Notes:
        –Ø–∫—â–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∏—Ö —ñ–Ω–¥–µ–∫—Å—ñ–≤ –±—ñ–ª—å—à–∞ –∑–∞ –æ–¥–∏–Ω, —Ç–æ –æ–±—Ä–∞–Ω–∏–π –Ω–æ–≤–∏–π —ñ–Ω–¥–µ–∫—Å –Ω–µ –ø–æ–≤–∏–Ω–µ–Ω –∑–±—ñ–≥–∞—Ç–∏—Å—è –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–º.

    Args:
        available_idxs (list): –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö —ñ–Ω–¥–µ–∫—Å—ñ–≤.
        preview_idx (int): –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π —ñ–Ω–¥–µ–∫—Å.

    Returns:
        int: –í–∏–ø–∞–¥–∫–æ–≤–∏–π —ñ–Ω–¥–µ–∫—Å.
    """
    if len(available_idxs) == 1:
        return available_idxs[0]

    # –Ø–∫—â–æ —ñ–Ω–¥–µ–∫—Å—ñ–≤ –±—ñ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ, —Ç–æ –æ–±–∏—Ä–∞—î—Ç—å—Å—è –Ω–æ–≤–∏–π —ñ–Ω–¥–µ–∫—Å
    wordpair_idx: int = random.choice(available_idxs)

    while wordpair_idx == preview_idx:
        wordpair_idx: int = random.choice(available_idxs)

    return wordpair_idx


def get_training_data(training_mode: str, word_items: list[dict], translation_items: list[dict]) -> dict[str, Any]:
    """–ü–æ–≤–µ—Ä—Ç–∞—î –¥–∞–Ω—ñ –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è, –≤–∏—Ö–æ–¥—è—á–∏ —ñ–∑ —Ç–∏–ø—É —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è.

    Args:
        training_mode (str): –¢–∏–ø —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è.
        word_items (list[dict]): –°–ø–∏—Å–æ–∫ —Å–ª—ñ–≤ —Å–ª–æ–≤–Ω–∏–∫–æ–≤–æ—ó –ø–∞—Ä–∏ –∑ —ó—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è–º–∏.
        translation_items (list[dict]): –°–ø–∏—Å–æ–∫ –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤ —Å–ª–æ–≤–Ω–∏–∫–æ–≤–æ—ó –ø–∞—Ä–∏ –∑ —ó—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è–º–∏.

    Returns:
        dict[str, Any]: Python-—Å–ª–æ–≤–Ω–∏–∫ —ñ–∑ –¥–∞–Ω–∏–º–∏:
            training_mode_name (str): –ù–∞–∑–≤–∞ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è.
            formatted_words (str): –í—ñ–¥—Ñ–æ—Ä–º–∞—Ç–æ–≤–∞–Ω—ñ —Å–ª–æ–≤–∞ —Å–ª–æ–≤–Ω–∏–∫–æ–≤–æ—ó –ø–∞—Ä–∏ —É –≤–∏–≥–ª—è–¥—ñ —Ä—è–¥–∫–∞.
            formatted_translations (str): –í—ñ–¥—Ñ–æ—Ä–º–∞—Ç–æ–≤–∞–Ω—ñ –ø–µ—Ä–µ–∫–ª–∞–¥–∏ —Å–ª–æ–≤–Ω–∏–∫–æ–≤–æ—ó –ø–∞—Ä–∏ —É –≤–∏–≥–ª—è–¥—ñ —Ä—è–¥–∫–∞.
            correct_translations (list[str]): –°–ø–∏—Å–æ–∫ –∫–æ—Ä–µ–∫—Ç–Ω–∏—Ö –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤ —É –Ω–∏–∂–Ω—å–æ–º—É —Ä–µ–≥—ñ—Å—Ç—Ä—ñ.
    """
    if training_mode == 'direct_translation':
        training_mode_name = '–ü—Ä—è–º–∏–π –ø–µ—Ä–µ–∫–ª–∞–¥ (W -> T)'
        formatted_words: str = format_word_items(word_items)
        formatted_translations: str = format_word_items(translation_items, is_translation_items=True)
        correct_translations: list[str] = [translation.get('translation').lower() for translation in translation_items]
    elif training_mode == 'reverse_translation':
        training_mode_name = '–ó–≤–æ—Ä–æ—Ç–Ω—ñ–π –ø–µ—Ä–µ–∫–ª–∞–¥ (T -> W)'
        formatted_words: str = format_word_items(translation_items, is_translation_items=True)
        formatted_translations: str = format_word_items(word_items)
        correct_translations: list[str] = [translation.get('word').lower() for translation in word_items]

    training_data: dict[str, Any] = {'training_mode_name': training_mode_name,
                                     'formatted_words': formatted_words,
                                     'formatted_translations': formatted_translations,
                                     'correct_translations': correct_translations}
    return training_data


def get_wordpair_idx_for_training(available_idxs: list, preview_wordpair_idx: int, is_use_current_words: bool) -> int:
    """–ü–æ–≤–µ—Ä—Ç–∞—î —ñ–Ω–¥–µ–∫—Å —Å–ª–æ–≤–Ω–∏–∫–æ–≤–æ—ó –ø–∞—Ä–∏ –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è.

    Notes:
        –Ø–∫—â–æ is_use_current_words=True, —Ç–æ –ø–æ–≤–µ—Ä—Ç–∞—î—Ç—å—Å—è –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–π —ñ–Ω–¥–µ–∫—Å,
        –≤ —ñ–Ω—à–æ–º—É —Ä–∞–∑—ñ –≤–∏–ø–∞–¥–∫–æ–≤–∏–π —ñ–∑ —Å–ø–∏—Å–∫—É –Ω–µ–≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏—Ö.

    Args:
        available_idxs (list): –°–ø–∏—Å–æ–∫ —ñ–Ω–¥–µ–∫—Å—ñ–≤, —è–∫—ñ —â–µ –Ω–µ –±—É–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ.
        preview_wordpair_idx (int): –ú–∏–Ω—É–ª–∏–π —ñ–Ω–¥–µ–∫—Å.
        is_use_current_words (bool): –ü—Ä–∞–ø–æ—Ä, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –ø–æ—Ç–æ—á–Ω–µ —Å–ª–æ–≤–æ(–∞) —á–∏ –æ–±—Ä–∞—Ç–∏ –Ω–æ–≤–µ.
    """
    if is_use_current_words:
        return preview_wordpair_idx

    # –í–∏–±—ñ—Ä –≤–∏–ø–∞–¥–∫–æ–≤–æ–≥–æ —ñ–Ω–¥–µ–∫—Å—É –∑ —Ç–∏—Ö, —â–æ —â–µ –Ω–µ –±—É–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ
    return get_random_wordpair_idx(available_idxs, preview_wordpair_idx)
